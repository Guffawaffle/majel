# Majel â€” STFC Fleet Intelligence System

*Named in honor of Majel Barrett-Roddenberry (1932â€“2008), the voice of Starfleet computers across four decades of Star Trek.*

A fleet management and AI advisor for **Star Trek Fleet Command**, powered by **Gemini** and **[Lex](https://github.com/Guffawaffle/lex)** episodic memory. The in-character assistant, **Ariadne** ("Aria"), combines CDN-sourced reference data, your personal fleet overlays, and full game/lore knowledge into a conversational interface that actually knows your fleet.

> **Status:** v0.5.0 alpha â€” functional, cloud-deployed, actively developed.
>
> **Production:** [majel-bbqfhcihga-uc.a.run.app](https://majel-bbqfhcihga-uc.a.run.app)

---

## Quick Start

```bash
# 1. Clone and install
git clone https://github.com/Guffawaffle/majel.git
cd majel
npm install

# 2. Configure
cp .env.example .env
# Edit .env â€” add your GEMINI_API_KEY (only required variable)

# 3. Run
npm run dev

# 4. Open http://localhost:3000
```

See [docs/SETUP.md](docs/SETUP.md) for detailed setup including PostgreSQL and cloud deployment.

---

## What It Does

Majel is a **five-view single-page application** with an LCARS-inspired UI:

| View | Purpose |
|------|---------|
| **Chat** | Conversational AI advisor with persistent memory. Ask about officers, crews, strategy, lore â€” anything. |
| **Catalog** | Browse 530+ ships and 278+ officers from the STFC CDN data pipeline. Overlay your own levels, tiers, and notes. |
| **Fleet** | Inline-editable fleet roster. Track power, rank, tier, level, and priority for every officer and ship you own. |
| **Drydock** | Build and manage ship loadouts. Assign officers to bridge seats, save presets, tag and search configurations. |
| **Diagnostics** | Natural-language query tool backed by AI. Ask questions about your data and get answers with SQL transparency. |

### Key Features

- **CDN-sourced reference data** â€” officer and ship catalogs synced from data.stfc.space, with canonical entity IDs (`cdn:officer:<gameId>`, `cdn:ship:<gameId>`)
- **Personal overlays** â€” your levels, tiers, notes, and target priorities stored separately from reference data. Never lost on re-sync.
- **Brute-force context injection** â€” reference data is injected directly into Gemini's system prompt. No RAG, no vector DB, no retrieval errors.
- **MicroRunner pipeline** â€” classifies each message, gates context injection by task type, and validates responses against the authority ladder
- **Conversation memory** â€” every turn is stored via Lex. Persists across restarts, supports semantic recall.
- **In-character** â€” Aria is the ship's computer. Dry wit, quiet authority, occasional Trek references.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Browser SPA                           â”‚
â”‚   5 views: Chat â”‚ Catalog â”‚ Fleet â”‚ Drydock â”‚ Diagnostics â”‚
â”‚              LCARS-inspired dark theme                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTP/JSON (56+ endpoints)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Express Server (:3000)                      â”‚
â”‚                                                           â”‚
â”‚  Auth:  4-tier RBAC (Ensign â†’ Admiral) + Bearer tokens    â”‚
â”‚  API:   Envelope pattern { ok, data|error, meta }         â”‚
â”‚                                                           â”‚
â”‚  /api/catalog/*    Officer & ship reference + overlays    â”‚
â”‚  /api/crew/*       Crew composition (ADR-025)             â”‚
â”‚  /api/targets/*    Fleet targets & goals                  â”‚
â”‚  /api/diagnostic/* AI-powered natural-language queries    â”‚
â”‚  /api/chat         Gemini conversation via MicroRunner    â”‚
â”‚  /api/sessions/*   Multi-session management               â”‚
â”‚  /api/settings/*   User preferences                       â”‚
â”‚  /api/models/*     Gemini model hot-swap (5 tiers)        â”‚
â”‚  /api/health       Status + version                       â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚              â”‚              â”‚
   â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gemini â”‚  â”‚PostgreSQLâ”‚  â”‚    Lex     â”‚
â”‚  2.5   â”‚  â”‚   16     â”‚  â”‚ Memory     â”‚
â”‚(5 modelâ”‚  â”‚reference â”‚  â”‚(PostgreSQL â”‚
â”‚ tiers, â”‚  â”‚overlays  â”‚  â”‚ frame      â”‚
â”‚ hot-   â”‚  â”‚docks     â”‚  â”‚ store,     â”‚
â”‚ swap)  â”‚  â”‚sessions  â”‚  â”‚ per-user   â”‚
â”‚        â”‚  â”‚settings  â”‚  â”‚ RLS)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Model

Majel uses a **reference + overlay** architecture (ADR-016):

- **Reference store** â€” immutable CDN-sourced data (stats, abilities, faction, rarity). Bulk-synced from data.stfc.space.
- **Overlay store** â€” your personal data (level, tier, rank, power, notes, targets). Survives re-syncs. Stored as sparse deltas.
- **Dock store** â€” ship loadouts with officer assignments, presets, and tags.

### Lex Memory Integration

Every conversation turn is stored as a Lex frame:
- **Persistent history** across server restarts
- **Semantic search** ("What did we discuss about Kirk?")
- **Timeline queries** (last 20 conversations)

Memory is workspace-isolated â€” Majel's DB lives at `.smartergpt/lex/` and never touches a global Lex installation.

---

## Configuration

### Required

| Variable | Description |
|----------|-------------|
| `GEMINI_API_KEY` | API key from [AI Studio](https://aistudio.google.com/apikey) |

### Optional

| Variable | Description | Default |
|----------|-------------|---------|
| `MAJEL_PORT` | Server port | `3000` |
| `LEX_WORKSPACE_ROOT` | Lex database location | `/srv/majel` |

---

## Scripts

```bash
npm run dev:full     # Start PostgreSQL + API server + Vite dev server (all-in-one)
npm run dev          # API server only with hot reload (tsx watch)
npm run build        # Compile TypeScript + copy static assets
npm start            # Production server (from dist/)
npm test             # Run test suite (1,361 server + 174 frontend tests via Vitest)
npm run typecheck    # Type-check without emitting
npm run local-ci     # Full CI pipeline: typecheck + coverage + build
npm run health       # Curl the health endpoint
```

### Cloud Operations

```bash
npm run cloud                    # Show all commands, tiers, and usage
npm run cloud:status             # Service status, URL, revision, scaling
npm run cloud:deploy             # Full pipeline: local-ci â†’ build â†’ deploy â†’ health
npm run cloud:logs               # Tail production logs
npm run cloud:metrics            # Log-based metrics (latency, errors, 1h window)
npm run cloud:costs              # Estimated monthly costs
npm run cloud:status -- --ax     # Structured JSON for AI agent consumption
```

See `npm run cloud` for the full 20-command reference with auth tiers.

---

## Project Structure

```
majel/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server/
â”‚   â”‚   â”œâ”€â”€ index.ts             # Express server bootstrap
â”‚   â”‚   â”œâ”€â”€ app-context.ts       # Dependency injection (AppState)
â”‚   â”‚   â”œâ”€â”€ config.ts            # Environment config resolver
â”‚   â”‚   â”œâ”€â”€ gemini.ts            # Gemini API + 5-tier model registry
â”‚   â”‚   â”œâ”€â”€ micro-runner.ts      # MicroRunner pipeline (classify â†’ gate â†’ validate)
â”‚   â”‚   â”œâ”€â”€ envelope.ts          # API response envelope (sendOk/sendFail + hints)
â”‚   â”‚   â”œâ”€â”€ auth.ts              # 4-tier RBAC middleware (ADR-019)
â”‚   â”‚   â”œâ”€â”€ user-store.ts        # User accounts + sessions
â”‚   â”‚   â”œâ”€â”€ memory.ts            # Lex memory integration
â”‚   â”‚   â”œâ”€â”€ memory-middleware.ts  # Per-user scoped memory (RLS)
â”‚   â”‚   â”œâ”€â”€ reference-store.ts   # CDN-sourced officer/ship data (read-only)
â”‚   â”‚   â”œâ”€â”€ overlay-store.ts     # User overlays (level, tier, notes)
â”‚   â”‚   â”œâ”€â”€ crew-store.ts         # Crew composition store (ADR-025)
â”‚   â”‚   â”œâ”€â”€ crew-types.ts        # Crew composition types (ADR-025)
â”‚   â”‚   â”œâ”€â”€ sessions.ts          # Multi-session management
â”‚   â”‚   â”œâ”€â”€ settings.ts          # User preferences store
â”‚   â”‚   â”œâ”€â”€ logger.ts            # Pino structured logging
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ core.ts          # /api, /api/health, /api/diagnostic
â”‚   â”‚       â”œâ”€â”€ chat.ts          # /api/chat, /api/history, /api/recall, /api/models
â”‚   â”‚       â”œâ”€â”€ catalog.ts       # /api/catalog/* (officers, ships, overlays, sync)
â”‚   â”‚       â”œâ”€â”€ crews.ts         # /api/crew/* (ADR-025 composition CRUD)
â”‚   â”‚       â”œâ”€â”€ targets.ts       # /api/targets/* (fleet goals)
â”‚   â”‚       â”œâ”€â”€ receipts.ts      # /api/import/* (import receipts)
â”‚   â”‚       â”œâ”€â”€ diagnostic-query.ts  # /api/diagnostic/* (AI query tool)
â”‚   â”‚       â”œâ”€â”€ sessions.ts      # /api/sessions/*
â”‚   â”‚       â””â”€â”€ settings.ts      # /api/settings/*
â”‚   â””â”€â”€ client/
â”‚       â”œâ”€â”€ index.html           # SPA shell + LCARS theme
â”‚       â”œâ”€â”€ app.js               # Router + tab management
â”‚       â”œâ”€â”€ api.js               # Fetch wrapper
â”‚       â”œâ”€â”€ chat.js, catalog.js, fleet.js, diagnostics.js
â”‚       â””â”€â”€ styles.css           # LCARS-inspired dark theme
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ cloud.ts                 # Cloud operations CLI (20 commands, AX mode)
â”œâ”€â”€ test/                        # 42 test files, 1,348 tests (Vitest)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ADR-001 through ADR-022  # Architecture Decision Records
â”‚   â”œâ”€â”€ AX-SCHEMA.md             # AI agent response format reference
â”‚   â”œâ”€â”€ PROMPT_GUIDE.md          # Prompt engineering reference
â”‚   â””â”€â”€ SETUP.md                 # Developer setup guide
â”œâ”€â”€ legacy/
â”‚   â””â”€â”€ majel.py                 # Original Python CLI prototype
â”œâ”€â”€ BACKLOG.md                   # Issue tracker + tech debt
â”œâ”€â”€ CHANGELOG.md                 # Release history
â”œâ”€â”€ CONTRIBUTING.md              # Contributor guidelines
â””â”€â”€ package.json
```

---

## Dependencies

| Package | Purpose |
|---------|---------|
| `@google/genai` | Gemini Gen AI SDK â€” 5 model tiers (flash-lite â†’ 3-pro-preview) |
| `@smartergpt/lex` | Episodic memory â€” PostgreSQL frame store with per-user RLS |
| `pg` | PostgreSQL 16 driver (Cloud SQL) |
| `better-sqlite3` | Local SQLite for reference data caches |
| `cookie-parser` | Session cookie middleware |
| `express` | HTTP server |
| `pino` / `pino-http` | Structured JSON logging |
| `dotenv` | Environment configuration |

---

## Privacy & Cost

- **Privacy**: Gemini paid tier â€” no training on prompts/responses. Fleet data in Cloud SQL with per-user row-level security.
- **Cost**: Target <$5/month. Gemini 2.5 Flash â‰ˆ$0.075/1M input tokens. Cloud Run scales to zero. Cloud SQL f1-micro.
- **Data sovereignty**: Each user's memory and fleet data is isolated via PostgreSQL RLS. Admin queries are audited.

---

## Lex Proof of Concept

Majel serves as a public proof-of-concept for [Lex](https://github.com/Guffawaffle/lex), an episodic memory framework for AI agents. The integration demonstrates:

- **Frame-based memory** â€” each conversation turn becomes a Lex frame with structured metadata
- **Semantic recall** â€” search past conversations by meaning, not just keywords
- **Per-user isolation** â€” PostgreSQL row-level security scopes all memory by user_id
- **Production deployment** â€” `PostgresFrameStore` runs in Cloud SQL with connection pooling

---

## License

ISC â€” see [LICENSE](LICENSE).

---

*Live long and prosper.* ğŸ––
