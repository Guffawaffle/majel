# Majel â€” STFC Fleet Intelligence System

*Named in honor of Majel Barrett-Roddenberry (1932â€“2008), the voice of Starfleet computers across four decades of Star Trek.*

A local fleet management and AI advisor for **Star Trek Fleet Command**, powered by **Gemini 2.5 Flash** and **[Lex](https://github.com/Guffawaffle/lex)** episodic memory. The in-character assistant, **Ariadne** ("Aria"), combines wiki-sourced reference data, your personal fleet overlays, and full game/lore knowledge into a conversational interface that actually knows your fleet.

> **Status:** v0.4.0 alpha â€” functional, local-only, actively developed.

---

## Quick Start

```bash
# 1. Clone and install
git clone https://github.com/Guffawaffle/majel.git
cd majel
npm install

# 2. Configure
cp .env.example .env
# Edit .env â€” add your GEMINI_API_KEY (only required variable)

# 3. Run
npm run dev

# 4. Open http://localhost:3000
```

See [docs/SETUP.md](docs/SETUP.md) for detailed setup.

---

## What It Does

Majel is a **five-view single-page application** with an LCARS-inspired UI:

| View | Purpose |
|------|---------|
| **Chat** | Conversational AI advisor with persistent memory. Ask about officers, crews, strategy, lore â€” anything. |
| **Catalog** | Browse 174 officers and 54 ships imported from the STFC Fandom wiki. Overlay your own levels, tiers, and notes. |
| **Fleet** | Inline-editable fleet roster. Track power, rank, tier, level, and priority for every officer and ship you own. |
| **Drydock** | Build and manage ship loadouts. Assign officers to bridge seats, save presets, tag and search configurations. |
| **Diagnostics** | Natural-language query tool backed by AI. Ask questions about your data and get answers with SQL transparency. |

### Key Features

- **Wiki-sourced reference data** â€” officer and ship catalogs imported from the STFC Fandom wiki, with canonical entity IDs (`wiki:officer:<pageId>`)
- **Personal overlays** â€” your levels, tiers, notes, and target priorities stored separately from reference data. Never lost on re-sync.
- **Brute-force context injection** â€” reference data is injected directly into Gemini's system prompt. No RAG, no vector DB, no retrieval errors.
- **MicroRunner pipeline** â€” classifies each message, gates context injection by task type, and validates responses against the authority ladder
- **Conversation memory** â€” every turn is stored via Lex. Persists across restarts, supports semantic recall.
- **In-character** â€” Aria is the ship's computer. Dry wit, quiet authority, occasional Trek references.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Browser SPA                           â”‚
â”‚   5 views: Chat â”‚ Catalog â”‚ Fleet â”‚ Drydock â”‚ Diagnostics â”‚
â”‚              LCARS-inspired dark theme                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTP/JSON (56 endpoints)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Express Server (:3000)                     â”‚
â”‚                                                           â”‚
â”‚  /api/catalog/*    Officer & ship reference + overlays    â”‚
â”‚  /api/dock/*       Drydock loadouts, presets, tags        â”‚
â”‚  /api/diagnostic/* AI-powered natural-language queries    â”‚
â”‚  /api/chat         Gemini conversation via MicroRunner    â”‚
â”‚  /api/sessions/*   Multi-session management               â”‚
â”‚  /api/settings/*   User preferences                       â”‚
â”‚  /api/health       Status + version                       â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚              â”‚              â”‚
   â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gemini â”‚  â”‚  SQLite   â”‚  â”‚    Lex     â”‚
â”‚  2.5   â”‚  â”‚ (4 DBs)  â”‚  â”‚ Memory DB  â”‚
â”‚ Flash  â”‚  â”‚reference â”‚  â”‚(workspace- â”‚
â”‚(brute  â”‚  â”‚settings  â”‚  â”‚ isolated,  â”‚
â”‚ force  â”‚  â”‚chat      â”‚  â”‚ semantic   â”‚
â”‚context)â”‚  â”‚behavior  â”‚  â”‚ recall)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Model

Majel uses a **reference + overlay** architecture (ADR-016):

- **Reference store** â€” immutable wiki-sourced data (stats, abilities, faction, rarity). Bulk-synced from the STFC Fandom wiki.
- **Overlay store** â€” your personal data (level, tier, rank, power, notes, targets). Survives re-syncs. Stored as sparse deltas.
- **Dock store** â€” ship loadouts with officer assignments, presets, and tags.

### Lex Memory Integration

Every conversation turn is stored as a Lex frame:
- **Persistent history** across server restarts
- **Semantic search** ("What did we discuss about Kirk?")
- **Timeline queries** (last 20 conversations)

Memory is workspace-isolated â€” Majel's DB lives at `.smartergpt/lex/` and never touches a global Lex installation.

---

## Configuration

### Required

| Variable | Description |
|----------|-------------|
| `GEMINI_API_KEY` | API key from [AI Studio](https://aistudio.google.com/apikey) |

### Optional

| Variable | Description | Default |
|----------|-------------|---------|
| `MAJEL_PORT` | Server port | `3000` |
| `LEX_WORKSPACE_ROOT` | Lex database location | `/srv/majel` |

---

## Scripts

```bash
npm run dev          # Development server with hot reload (tsx watch)
npm run build        # Compile TypeScript + copy static assets
npm start            # Production server (from dist/)
npm test             # Run test suite (512 tests via Vitest)
npm run typecheck    # Type-check without emitting
npm run local-ci     # Full CI pipeline: typecheck + coverage + build
npm run health       # Curl the health endpoint
```

---

## Project Structure

```
majel/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server/
â”‚   â”‚   â”œâ”€â”€ index.ts             # Express server bootstrap
â”‚   â”‚   â”œâ”€â”€ gemini.ts            # Gemini API + system prompt builder
â”‚   â”‚   â”œâ”€â”€ micro-runner.ts      # MicroRunner pipeline (classify â†’ gate â†’ validate)
â”‚   â”‚   â”œâ”€â”€ reference-store.ts   # Wiki-sourced officer/ship data (read-only)
â”‚   â”‚   â”œâ”€â”€ overlay-store.ts     # User overlays (level, tier, notes)
â”‚   â”‚   â”œâ”€â”€ dock-store.ts        # Drydock loadouts + presets
â”‚   â”‚   â”œâ”€â”€ wiki-ingest.ts       # STFC Fandom wiki scraper/importer
â”‚   â”‚   â”œâ”€â”€ memory.ts            # Lex memory integration
â”‚   â”‚   â”œâ”€â”€ behavior-store.ts    # Behavioral correction rules
â”‚   â”‚   â”œâ”€â”€ sessions.ts          # Multi-session management
â”‚   â”‚   â”œâ”€â”€ settings.ts          # User preferences store
â”‚   â”‚   â”œâ”€â”€ config.ts            # Environment config
â”‚   â”‚   â”œâ”€â”€ logger.ts            # Pino structured logging
â”‚   â”‚   â”œâ”€â”€ envelope.ts          # API response envelope
â”‚   â”‚   â”œâ”€â”€ app-context.ts       # Dependency injection context
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ core.ts          # /api, /api/health, /api/chat, /api/history, /api/recall
â”‚   â”‚       â”œâ”€â”€ catalog.ts       # /api/catalog/* (officers, ships, overlays, sync)
â”‚   â”‚       â”œâ”€â”€ docks.ts         # /api/dock/* (loadouts, presets, tags)
â”‚   â”‚       â”œâ”€â”€ diagnostic-query.ts  # /api/diagnostic/* (AI query tool)
â”‚   â”‚       â”œâ”€â”€ chat.ts          # /api/chat (POST)
â”‚   â”‚       â”œâ”€â”€ sessions.ts      # /api/sessions/*
â”‚   â”‚       â””â”€â”€ settings.ts      # /api/settings/*
â”‚   â””â”€â”€ client/
â”‚       â”œâ”€â”€ index.html           # SPA shell + LCARS theme
â”‚       â”œâ”€â”€ app.js               # Router + tab management
â”‚       â”œâ”€â”€ api.js               # Fetch wrapper
â”‚       â”œâ”€â”€ chat.js              # Chat view
â”‚       â”œâ”€â”€ catalog.js           # Catalog browser view
â”‚       â”œâ”€â”€ fleet.js             # Fleet roster view (inline editing)
â”‚       â”œâ”€â”€ drydock.js           # Drydock loadout builder
â”‚       â”œâ”€â”€ diagnostics.js       # AI diagnostic query view
â”‚       â”œâ”€â”€ sessions.js          # Session management
â”‚       â”œâ”€â”€ confirm-dialog.js    # Reusable confirmation modal
â”‚       â””â”€â”€ styles.css           # LCARS-inspired dark theme
â”œâ”€â”€ test/                        # 13 test files, 512 tests (Vitest)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ADR-001 through ADR-017  # Architecture Decision Records
â”‚   â”œâ”€â”€ PROMPT_GUIDE.md          # Prompt engineering reference
â”‚   â””â”€â”€ SETUP.md                 # Developer setup guide
â”œâ”€â”€ legacy/
â”‚   â”œâ”€â”€ majel.py                 # Original Python CLI prototype
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ .env.example
â””â”€â”€ CHANGELOG.md
```

---

## Dependencies

| Package | Purpose |
|---------|---------|
| `@google/generative-ai` | Gemini 2.5 Flash SDK |
| `@smartergpt/lex` | Episodic memory (conversation persistence + recall) |
| `better-sqlite3` | SQLite driver for reference, overlay, dock, and settings stores |
| `express` | HTTP server |
| `pino` / `pino-http` | Structured JSON logging |
| `dotenv` | Environment configuration |

---

## Privacy & Cost

- **Privacy**: Gemini paid tier â€” no training on prompts/responses. All fleet data stored locally in SQLite.
- **Cost**: Target <$2/month. Gemini 2.5 Flash is â‰ˆ$0.075/1M input tokens.
- **Local-only**: Nothing leaves your machine except Gemini API calls.

---

## Lex Proof of Concept

Majel serves as a public proof-of-concept for [Lex](https://github.com/Guffawaffle/lex), an episodic memory framework for AI agents. The integration demonstrates:

- **Frame-based memory** â€” each conversation turn becomes a Lex frame with structured metadata
- **Semantic recall** â€” search past conversations by meaning, not just keywords
- **Workspace isolation** â€” Majel's memory DB is separate from any global Lex installation
- **Zero configuration** â€” `createFrameStore()` handles all SQLite setup automatically

---

## License

ISC â€” see [LICENSE](LICENSE).

---

*Live long and prosper.* ğŸ––
